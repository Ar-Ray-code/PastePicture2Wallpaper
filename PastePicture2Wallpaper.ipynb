{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwUzOv_YJ5c_"
      },
      "source": [
        "# PastePicture2Wallpaper\n",
        "\n",
        "壁紙作成のための線画作成ツールです\n",
        "\n",
        "以下のパラメータで値を弄ってください\n",
        "\n",
        "- depth_threshold: 出力された深度情報をもとに線画化するための閾値\n",
        "<!-- - image_upload_option: 画像をアップロードする方法 -->\n",
        "  <!-- - `Upload from device`: デバイスからアップロード -->\n",
        "  <!-- - `URL`: URLからダウンロード -->\n",
        "  <!-- - `Mount Drive`: Google Driveのマウントを行う -->\n",
        "<!-- - path_or_url: ダウンロード先のURLかマウント先のデバイスのパスを指定(Upload from devieの場合は無視されます) -->\n",
        "- mode: 線画処理のモード\n",
        "  - Anime : アニメ風の輪郭がはっきりとしている画像向け\n",
        "- OS: 壁紙のOSの種類によって出力される線画の雰囲気が少し変わります\n",
        "  - Mac風(灰色):パステルカラーの背景に合わせて半透明の灰色線画を出力\n",
        "  - Mac風(白色):鮮やかな背景に半透明の白線画を出力\n",
        "  - Windows風: 水色の背景にさらに明るい水色半透明の線画を出力\n",
        "  - Ubuntu風: 紫-桃色の背景に馴染む桃色半透明の線画を出力\n",
        "\n",
        "![](https://raw.githubusercontent.com/Ar-Ray-code/PastePicture2Wallpaper/main/images_for_readme/export-variation.png)\n",
        "\n",
        "> デバイスからのアップロードのみ受け付けています\n",
        "> \n",
        "> 直接URLを指定する場合は4番目のコードセルのURLを変更してコメントアウトを外し、以降のセルを実行（Ctrl+F10） を行ってください"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9UIXNyyXdKaO"
      },
      "outputs": [],
      "source": [
        "depth_threshold = 150 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "\n",
        "# image_upload_option = 'Upload from device' #@param [\"Upload from device\", \"URL\", \"Mount Drive\"] {allow-input: true}\n",
        "# path_or_url = \"/content/sample.jpg\"#@param {type:\"string\"}\n",
        "\n",
        "mode = 'Anime' #@param [\"Anime\"] {allow-input: true}\n",
        "OS =  'Ubuntu' #@param [\"Ubuntu\",\"Windows\",\"Mac-White\",\"Mac-Gray\"] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PbJjVsrTrzK"
      },
      "outputs": [],
      "source": [
        "# Upload from device\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#@markdown ### アップロードを (Choose Files)から行ってください\n",
        "#@markdown Driveのマウントの場合はこのステップを飛ばして、新しくコードセルを作成して、`/content`に対象ファイルをコピーしてください\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "maDiodVfAc1F"
      },
      "outputs": [],
      "source": [
        "#@markdown ###URLを指定する場合はこちらを編集し、upload.jpgで保存すること\n",
        "# !rm sample.jpg\n",
        "# !wget \"https://drive.google.com/uc?export=download&id=1M1eDdinWr-aPT28cyOo01LlMFUnsBbRQ\" -O upload.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LofUpIu2f2bJ"
      },
      "outputs": [],
      "source": [
        "!custom_path=basename path_or_url\n",
        "!mv `basename path_or_url` /content/upload.jpg\n",
        "!ffmpeg -i *.png upload.jpg\n",
        "!ffmpeg -i *.jpg upload.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z81Rg6PoAhDc"
      },
      "outputs": [],
      "source": [
        "!pip install \\\n",
        "    tensorflow==2.8.0 \\\n",
        "    tensorflow-hub==0.12.0 \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03GuyT13CK4Y",
        "outputId": "dac2f1ee-5af6-43ed-87b5-8f9ffd759e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "module = hub.load(\"https://tfhub.dev/intel/midas/v2_1_small/1\", tags=['serve'])\n",
        "model = module.signatures['serving_default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bxBmGrkbCNoT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 画像読み込み\n",
        "image = cv2.imread('/content/upload.jpg')\n",
        "\n",
        "# リサイズ\n",
        "resize_image = cv2.resize(image, (256, 256))\n",
        "\n",
        "# 正規化\n",
        "resize_image = cv2.cvtColor(resize_image, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "# 形状変更\n",
        "resize_image = resize_image.transpose(2, 0, 1)\n",
        "resize_image = resize_image.reshape(1, 3, 256, 256)\n",
        "\n",
        "# tensor形式へ変換\n",
        "tensor = tf.convert_to_tensor(resize_image, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rtxt6M8KCPG5"
      },
      "outputs": [],
      "source": [
        "result = model(tensor)\n",
        "predict_result = result['default'].numpy()\n",
        "predict_result = np.squeeze(predict_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEoF2RQECR0D"
      },
      "outputs": [],
      "source": [
        "# オリジナル画像のサイズにリサイズ\n",
        "predict_result = cv2.resize(predict_result, (image.shape[1], image.shape[0]))\n",
        "\n",
        "# 最大値が255になるよう変換\n",
        "depth_max = predict_result.max()\n",
        "data = ((predict_result / depth_max) * 255).astype(np.uint8)\n",
        "\n",
        "# カラーマップ画像へ変換\n",
        "color_map = cv2.applyColorMap(data, cv2.COLORMAP_TURBO)\n",
        "\n",
        "# 表示\n",
        "plt.imshow(color_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SZ2-AmlMe7Kd"
      },
      "outputs": [],
      "source": [
        "class image_utils:\n",
        "    def median_filter(self, src, ksize):\n",
        "        d = int((ksize-1)/2)\n",
        "        h, w = src.shape[0], src.shape[1]\n",
        "\n",
        "        dst = src.copy()\n",
        "\n",
        "        for y in range(d, h - d):\n",
        "            for x in range(d, w - d):\n",
        "                dst[y][x] = np.median(src[y-d:y+d+1, x-d:x+d+1])\n",
        "        return dst\n",
        "\n",
        "    def export_edges_anime(self, image_raw: np.ndarray, depth_data: np.ndarray, threshold: int = 150):\n",
        "        mask = depth_data > threshold\n",
        "        # maskを二値化\n",
        "        mask = mask.astype(np.uint8) * 255\n",
        "\n",
        "        # imageとmaskの合成\n",
        "        result = cv2.bitwise_and(image_raw, image_raw, mask=mask)\n",
        "        result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
        "        # メディアンフィルタ\n",
        "        result = self.median_filter(result, ksize=5)\n",
        "        # Canny輪郭検出\n",
        "        edges = cv2.Canny(result, 199, 200)\n",
        "        # MorphologyEx\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        # edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
        "        edges = cv2.morphologyEx(edges, cv2.MORPH_GRADIENT, kernel)\n",
        "\n",
        "        # 色の反転\n",
        "        edges = cv2.bitwise_not(edges)\n",
        "        edges = edges.astype(np.uint8) * 255 * 255\n",
        "        edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        return edges\n",
        "\n",
        "    # 白を透明にして色付きを半透明の白にする\n",
        "    def white2transparent(self, input_image: np.ndarray, os_type: str='Ubuntu'):\n",
        "        if os_type == 'Ubuntu':\n",
        "            image_png = cv2.cvtColor(input_image, cv2.COLOR_RGB2RGBA)\n",
        "            for i in range(image_png.shape[0]):\n",
        "                for j in range(image_png.shape[1]):\n",
        "                    if image_png[i][j][0] == 255 and image_png[i][j][1] == 255 and image_png[i][j][2] == 255:\n",
        "                        image_png[i][j][3] = 0\n",
        "                    else:\n",
        "                        image_png[i][j][0] = 255\n",
        "                        image_png[i][j][1] = 200\n",
        "                        image_png[i][j][2] = 255\n",
        "                        image_png[i][j][3] = 200\n",
        "        elif os_type == 'Windows':\n",
        "            image_png = cv2.cvtColor(input_image, cv2.COLOR_RGB2RGBA)\n",
        "            for i in range(image_png.shape[0]):\n",
        "                for j in range(image_png.shape[1]):\n",
        "                    if image_png[i][j][0] == 255 and image_png[i][j][1] == 255 and image_png[i][j][2] == 255:\n",
        "                        image_png[i][j][3] = 0\n",
        "                    else:\n",
        "                        image_png[i][j][0] = 200\n",
        "                        image_png[i][j][1] = 255\n",
        "                        image_png[i][j][2] = 255\n",
        "                        image_png[i][j][3] = 200\n",
        "        elif os_type == 'Mac-White':\n",
        "            image_png = cv2.cvtColor(input_image, cv2.COLOR_RGB2RGBA)\n",
        "            for i in range(image_png.shape[0]):\n",
        "                for j in range(image_png.shape[1]):\n",
        "                    if image_png[i][j][0] == 255 and image_png[i][j][1] == 255 and image_png[i][j][2] == 255:\n",
        "                        image_png[i][j][3] = 0\n",
        "                    else:\n",
        "                        image_png[i][j][0] = 200\n",
        "                        image_png[i][j][1] = 200\n",
        "                        image_png[i][j][2] = 200\n",
        "                        image_png[i][j][3] = 200\n",
        "        elif os_type == 'Mac-Gray':\n",
        "            image_png = cv2.cvtColor(input_image, cv2.COLOR_RGB2RGBA)\n",
        "            for i in range(image_png.shape[0]):\n",
        "                for j in range(image_png.shape[1]):\n",
        "                    if image_png[i][j][0] == 255 and image_png[i][j][1] == 255 and image_png[i][j][2] == 255:\n",
        "                        image_png[i][j][3] = 0\n",
        "                    else:\n",
        "                        image_png[i][j][0] = 70\n",
        "                        image_png[i][j][1] = 70\n",
        "                        image_png[i][j][2] = 70\n",
        "                        image_png[i][j][3] = 200\n",
        "        else:\n",
        "            print(\"cannot detect wallpaper OS\")\n",
        "        return image_png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "akicp1XSYg7C"
      },
      "outputs": [],
      "source": [
        "image_utils_class = image_utils()\n",
        "\n",
        "image = image_utils_class.export_edges_anime(image_raw=image, depth_data=data, threshold=depth_threshold)\n",
        "\n",
        "#@markdown ## export_edges_anime関数\n",
        "#@markdown ### 引数一覧\n",
        "#@markdown - image_raw: 画像（読み込み時のまま）\n",
        "#@markdown - depth_data: 深度データ(2次元のndarray・0~255)\n",
        "#@markdown - threshold: 深度の閾値（0~255・int型）\n",
        "#@markdown\n",
        "#@markdown ### 出力一覧\n",
        "#@markdown - image: マスク済み画像\n",
        "#@markdown\n",
        "#@markdown　---\n",
        "#@markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "q-H83_5UJC54"
      },
      "outputs": [],
      "source": [
        "image_utils_class = image_utils()\n",
        "image_png = image_utils_class.white2transparent(image, OS)\n",
        "\n",
        "#@markdown ## white2transparent関数\n",
        "#@markdown 白領域を透明化する関数（色付きは半透明の白になります）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Kg-Zb97tdjBe",
        "outputId": "c89cfdc5-714f-4c72-bfa8-c11759607f4d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_86370028-97c2-4155-ba2e-33fd43cec38e\", \"result.png\", 79513)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imsave(\"/content/result.png\",image_png)\n",
        "from google.colab import files\n",
        "files.download('result.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nU4eubO3EveY",
        "outputId": "d73d8483-133e-46ef-f6c3-af6f1c9798bb"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41e2439b-cfb7-451d-81dd-ebd5299520d3\", \"depth_result.png\", 359230)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Export depth\n",
        "#@markdown convert.pyで深度情報を確認する時はこのセルを実行して`depth_result.png`をダウンロードします。\n",
        "\n",
        "# # v----この行以下をコメントアウト--------v\n",
        "# export_png = np.zeros((data.shape[0], data.shape[1], 3))\n",
        "# export_png[:,:,0] = data/255\n",
        "# export_png[:,:,1] = data/255\n",
        "# export_png[:,:,2] = data/255\n",
        "\n",
        "# plt.imsave(\"/content/depth_result.png\",export_png)\n",
        "# files.download('depth_result.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PastePicture2Wallpaper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
